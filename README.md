# ğŸš€ Enterprise Web Scraper & Monitor

A powerful, enterprise-grade web scraping and monitoring system with AI-powered features, built for automated change detection, RAG chat, and n8n integration.

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## âœ¨ Features

### Core Scraping
- ğŸŒ **Multi-page crawling** with intelligent link extraction
- ğŸ“Š **Change detection** using content hashing
- â° **Scheduled monitoring** with customizable intervals
- ğŸ¯ **Smart filtering** (same-domain validation, www handling)

### Enterprise Features
- ğŸ¤– **Headless Browser (Playwright)** - Render JavaScript SPAs
- ğŸ”„ **Smart Proxy Rotation** - Avoid IP bans
- ğŸ­ **Anti-Fingerprinting** - Random User-Agents
- ğŸ’¬ **RAG Chat** - Ask questions about website content using AI
- ğŸ“¸ **Screenshot Monitoring** - Visual change tracking
- ğŸ” **Visual Diffing** - Side-by-side content comparison

### Integrations
- ğŸ”Œ **n8n Ready** - Full API for workflow automation
- ğŸŒ **ngrok Support** - Secure public tunnels
- ğŸ“ˆ **Analytics Dashboard** - Visual insights & trends

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web UI        â”‚  (Flask - Port 5000)
â”‚   localhost     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€> Scheduler (Background Jobs)
         â”‚
         â”œâ”€â”€â”€â”€â”€> Storage (SQLite)
         â”‚
         â””â”€â”€â”€â”€â”€> Scraper Module
                     â”‚
                     â”œâ”€> Playwright (JS Rendering)
                     â”œâ”€> BeautifulSoup (HTML Parsing)
                     â””â”€> Analyzer (OpenAI Integration)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Server    â”‚  (Flask - Port 5001)
â”‚   n8n Gateway   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- OpenAI API Key (for AI features)
- Git

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/enterprise-scraper.git
cd enterprise-scraper

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
.\venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
playwright install chromium
```

### Configuration

1. **Proxy Setup** (Optional)
   Edit `scraper.py` and add your proxy URLs:
   ```python
   PROXIES = [
       "http://user:pass@proxy1:port",
       "http://user:pass@proxy2:port",
   ]
   ```

2. **OpenAI API Key**
   - Set via UI when using AI features
   - Or set environment variable: `OPENAI_API_KEY`

### Running

```bash
# Start both UI and API servers
.\run.bat  # Windows
# Or manually:
python app.py          # Terminal 1 (UI)
python scraper_api.py  # Terminal 2 (API)
```

Access the application:
- **Web UI**: http://localhost:5000
- **API**: http://localhost:5001

## ğŸ“– Usage Guide

### 1. Monitor a Website

1. Open http://localhost:5000
2. Click "Monitor" tab
3. Enter website URL
4. Set OpenAI API key
5. Choose monitoring interval
6. Click "Start Monitoring"

### 2. Chat with Website (RAG)

1. Go to "Chat (RAG)" tab
2. Enter the root URL of a monitored site
3. Provide OpenAI API key
4. Ask questions like:
   - "What is the most recent release?"
   - "Give me the URL for version 25.11"
   - "What changed in the latest update?"

### 3. n8n Integration

See [N8N_INTEGRATION_GUIDE.md](N8N_INTEGRATION_GUIDE.md) for complete workflow examples.

**Example API Call:**
```bash
curl -X POST http://localhost:5001/scrape \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://example.com",
    "render_js": true,
    "use_proxy": false
  }'
```

## ğŸ”§ API Endpoints

### Scraping
- `POST /scrape` - Scrape single page
- `POST /scrape-complete` - Full site crawl
- `POST /screenshot` - Take screenshot

### Analysis
- `POST /chat` - RAG chat with content
- `POST /diff` - Visual diff of two texts

### Utility
- `GET /health` - Health check
- `GET /info` - API information

Full API documentation: [ENTERPRISE_FEATURES.md](ENTERPRISE_FEATURES.md)

## ğŸ“Š Database Schema

**Tables:**
- `pages` - Monitored pages and metadata
- `scrape_history` - Full scraping history with content
- `change_events` - Detected changes log
- `scrape_runs` - Performance metrics
- `schedules` - Monitoring schedules
- `site_summaries` - AI-generated summaries

## ğŸ› ï¸ Advanced Configuration

### Headless Browser Options
```python
# In scraper.py - fetch_page_playwright()
browser_args = {
    'headless': True,  # Run in background
    'args': ['--no-sandbox']  # Additional Chrome flags
}
```

### Scraping Limits
```python
# In app.py - crawl_and_scrape()
MAX_PAGES = 20  # Max pages per crawl
```

## ğŸ“ Project Structure

```
enterprise-scraper/
â”œâ”€â”€ app.py                      # Main UI server
â”œâ”€â”€ scraper_api.py              # API server
â”œâ”€â”€ scraper.py                  # Core scraping logic
â”œâ”€â”€ analyzer.py                 # AI analysis
â”œâ”€â”€ storage.py                  # Database operations
â”œâ”€â”€ scheduler.py                # Job scheduling
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html              # Web UI
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css
â”‚   â”œâ”€â”€ script.js
â”‚   â””â”€â”€ screenshots/            # Saved screenshots
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.bat                     # Startup script
â””â”€â”€ ENTERPRISE_FEATURES.md      # Feature documentation
```

## ğŸ› Troubleshooting

### "Changes not detected"
- Websites must actually change for detection
- Check Analytics tab for change history
- See [CHANGE_DETECTION_STATUS.md](CHANGE_DETECTION_STATUS.md)

### "RAG Chat not working"
- Ensure server restarted after updates
- Check database has content (not just hashes)
- Use exact root URL from Monitor tab
- See [RAG_IMPROVEMENTS.md](RAG_IMPROVEMENTS.md)

### Port Already in Use
```bash
# Windows: Find and kill process
netstat -ano | findstr :5000
taskkill /F /PID <PID>
```

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- **Playwright** - Headless browser automation
- **BeautifulSoup** - HTML parsing
- **OpenAI** - AI-powered features
- **Flask** - Web framework

## ğŸ”— Resources

- [Documentation](ENTERPRISE_FEATURES.md)
- [n8n Integration Guide](N8N_INTEGRATION_GUIDE.md)
- [Change Detection Guide](CHANGE_DETECTION_STATUS.md)
- [RAG Improvements](RAG_IMPROVEMENTS.md)

---

**Built with â¤ï¸ for enterprise web monitoring**
